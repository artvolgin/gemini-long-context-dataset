{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import caching\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "from tqdm import tqdm\n",
    "import webvtt\n",
    "import pprint\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Upload files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read files from local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials_cs224n_2019 = pd.read_pickle('cs224n-2019/df_materials.pkl')\n",
    "df_materials_cs224n_2024 = pd.read_pickle('cs224n-2024/df_materials.pkl')\n",
    "df_materials_cs231n_2024 = pd.read_pickle('cs231n-2024/df_materials.pkl')\n",
    "df_youtube_cs224n_2024 = pd.read_pickle('cs224n-2024/df_youtube.pkl')\n",
    "df_youtube_cs224n_2019 = pd.read_pickle('cs224n-2019/df_youtube.pkl')\n",
    "df_youtube_cs231n_2024 = pd.read_pickle('cs231n-2024/df_youtube.pkl')\n",
    "\n",
    "df_materials_cs224n_2019['course'] = 'cs224n-2019'\n",
    "df_materials_cs224n_2024['course'] = 'cs224n-2024'\n",
    "df_materials_cs231n_2024['course'] = 'cs231n-2024'\n",
    "\n",
    "df_youtube_cs224n_2024['course'] = 'cs224n-2024'\n",
    "df_youtube_cs224n_2024['type'] = 'youtube'\n",
    "\n",
    "df_youtube_cs224n_2019['course'] = 'cs224n-2019'\n",
    "df_youtube_cs224n_2019['type'] = 'youtube'\n",
    "\n",
    "df_youtube_cs231n_2024['course'] = 'cs231n-2024'\n",
    "df_youtube_cs231n_2024['type'] = 'youtube'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials = pd.concat([df_materials_cs224n_2019,\n",
    "                          df_materials_cs224n_2024,\n",
    "                          df_materials_cs231n_2024,\n",
    "                          df_youtube_cs224n_2024,\n",
    "                          df_youtube_cs224n_2019,\n",
    "                          df_youtube_cs231n_2024], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-convertable extensions\n",
    "remove_extensions = {'.pkl', '.mp4', '.png', '.sh', '.jpg', '.bat', '.en', '.conll', '.yml', '.zh',\n",
    "                     '.es', '.tsv', '.vocab', '.json', '.model', '.PNG', '.DS_Store', '.zip'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials = df_materials[(df_materials['file_path'] != 'None')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials = df_materials[~df_materials['extension'].isin(remove_extensions)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Why do we have duplicates?\n",
    "df_materials = df_materials.drop_duplicates().reset_index(drop=True)\n",
    "print(len(df_materials))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove youtube links\n",
    "df_materials = df_materials[~df_materials['file_path'].str.contains('www.youtube.com')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_materials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbformat\n",
    "from nbconvert import ScriptExporter\n",
    "\n",
    "def convert_ipynb_to_py(ipynb_file, output_dir=None):\n",
    "    \"\"\"\n",
    "    Convert a Jupyter Notebook (.ipynb) file to a Python (.py) file.\n",
    "    \n",
    "    Args:\n",
    "        ipynb_file (str): Path to the .ipynb file to convert.\n",
    "        output_dir (str, optional): Directory to save the .py file. Defaults to the current directory.\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the generated .py file.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the .ipynb file does not exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(ipynb_file):\n",
    "        raise FileNotFoundError(f\"The file '{ipynb_file}' does not exist.\")\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = os.path.dirname(ipynb_file)\n",
    "    \n",
    "    # Create an instance of ScriptExporter\n",
    "    script_exporter = ScriptExporter()\n",
    "    \n",
    "    # Parse the notebook content\n",
    "    with open(ipynb_file, 'r', encoding='utf-8') as f:\n",
    "        notebook_content = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    # Convert the notebook to script\n",
    "    script_content, _ = script_exporter.from_notebook_node(notebook_content)\n",
    "    \n",
    "    # Generate output file path\n",
    "    base_name = os.path.splitext(os.path.basename(ipynb_file))[0]\n",
    "    py_file_path = os.path.join(output_dir, f\"{base_name}.py\")\n",
    "    \n",
    "    # Write the script content to the .py file\n",
    "    with open(py_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(script_content)\n",
    "    \n",
    "    return py_file_path\n",
    "\n",
    "# Convert all Jupyter Notebooks to Python scripts\n",
    "list_ipynb = df_materials[df_materials['extension'] == '.ipynb']['file_path'].tolist()\n",
    "\n",
    "# Example usage:\n",
    "for ipynb_path in list_ipynb:\n",
    "    try:\n",
    "        py_file = convert_ipynb_to_py(ipynb_path, 'cs224n-2024/website_materials' )\n",
    "        print(f\"Converted to Python file: {py_file}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "\n",
    "df_materials.loc[df_materials['extension'] == '.ipynb', 'extension'] = '.py'\n",
    "df_materials.loc[df_materials['extension'] == '.py', 'file_path'] = df_materials.loc[\n",
    "    df_materials['extension'] == '.py', 'file_path'\n",
    "].apply(lambda x: x.replace('.ipynb', '.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    str: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred while processing the PDF: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webvtt\n",
    "\n",
    "def convert_vtt_to_string(vtt_file_path, include_timecodes=False):\n",
    "    \"\"\"\n",
    "    Converts a .vtt file to a string, optionally including timecodes.\n",
    "\n",
    "    Args:\n",
    "        vtt_file_path (str): Path to the .vtt file to be converted.\n",
    "        include_timecodes (bool): Whether to include timecodes in the output.\n",
    "\n",
    "    Returns:\n",
    "        str: The processed content of the .vtt file as a string.\n",
    "    \"\"\"\n",
    "    if not vtt_file_path.endswith(\".vtt\"):\n",
    "        raise ValueError(\"Input file must be a .vtt file.\")\n",
    "    \n",
    "    transcript = []\n",
    "    previous_line = None\n",
    "\n",
    "    # Read and process the .vtt file\n",
    "    vtt = webvtt.read(vtt_file_path)\n",
    "\n",
    "    for caption in vtt:\n",
    "        # Get timecodes if required\n",
    "        timecode = f\"{caption.start} --> {caption.end}\" if include_timecodes else \"\"\n",
    "\n",
    "        # Clean and split the caption text\n",
    "        lines = caption.text.strip().splitlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            # Skip duplicate lines\n",
    "            if line and line != previous_line:\n",
    "                if include_timecodes:\n",
    "                    transcript.append(f\"{timecode} {line}\")\n",
    "                else:\n",
    "                    transcript.append(line)\n",
    "                previous_line = line\n",
    "\n",
    "    # Join the transcript lines into a single string\n",
    "    return \"\\n\".join(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_as_string(file_path):\n",
    "    \"\"\"\n",
    "    Reads the content of a file and returns it as a string.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the file as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    if file_path.endswith('.pdf'):\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    \n",
    "    if file_path.endswith('.vtt'):\n",
    "        return convert_vtt_to_string(file_path)\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            # Open the file and read its content\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            return content\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Error: The file at {file_path} was not found.\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An error occurred while reading the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files_str = []\n",
    "for i in tqdm(range(len(df_materials))):\n",
    "    try:\n",
    "        file_str = read_file_as_string(df_materials.loc[i, 'file_path'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(i)\n",
    "        file_str = None\n",
    "    list_files_str.append(file_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials['file_str'] = list_files_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_materials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials = df_materials[df_materials['file_str'].notna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_materials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = 'GEMINI_API_KEY'\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "GEMINI_MODEL = 'models/gemini-1.5-flash-002'\n",
    "# GEMINI_MODEL = 'models/gemini-1.5-pro-002'\n",
    "\n",
    "model = genai.GenerativeModel(model_name=GEMINI_MODEL)\n",
    "print(f'Model {model.model_name} loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tokens = []\n",
    "retry_attempts = 1  # Number of retry attempts\n",
    "\n",
    "for file in tqdm(df_materials['file_str'].tolist(), desc=\"Calculating number of tokens\"):\n",
    "    \n",
    "    if file:\n",
    "\n",
    "        attempt = 0\n",
    "        success = False\n",
    "    \n",
    "        while attempt < retry_attempts and not success:\n",
    "            try:\n",
    "                tokens = model.count_tokens(file).total_tokens\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                if attempt < retry_attempts:\n",
    "                    print(f\"Error with {file[:100]}, retrying... ({attempt}/{retry_attempts})\")\n",
    "                    time.sleep(1)  # Optional: small delay between retries\n",
    "                else:\n",
    "                    tokens = 0\n",
    "                    print(f\"Failed to process {file[:100]} after {retry_attempts} attempts. Error: {e}\")\n",
    "    \n",
    "    else:\n",
    "        tokens = 0\n",
    "    \n",
    "    list_tokens.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials['num_tokens'] = list_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials['file'] = df_materials['file_path'].apply(lambda x: x.split('/')[-1])\n",
    "df_materials['file'] = df_materials['file'].str.replace('web.stanford.edu_class_', '')\n",
    "df_materials['file'] = df_materials['file'].str.replace('drive.usercontent.google.com_download_id=', '')\n",
    "df_materials['file'] = df_materials['course'] + '/' + df_materials['file']\n",
    "\n",
    "def add_file_name_course(row):\n",
    "    return f\"=== File: {row['file']} === \\n === Name: {row['name']} === \\n === Course: {row['course']} === \\n\\n {row['file_str']} \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials['file_str'] = df_materials.apply(add_file_name_course, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_materials.to_pickle('df_materials_str.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
